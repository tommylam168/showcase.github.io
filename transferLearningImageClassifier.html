<!DOCTYPE html>
<html>
<head>
<title>Build an Image Classifier</title>
<style>
body{font-family:helvetica,arial,sans-serif;margin:2em}
h1{font-style:italic;color:#FF6F00}
#status{font-size:150%}
video{clear:both;display:block;margin:10px;background:#000;width:640px;height:480px}
button{padding:10px;float:left;margin:5px 3px 5px 10px}
.removed{display:none}
</style>
<script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>
</head>
<body>
<h1>Teachable Machine</h1>
<p id='status'>Model is loading.</p>
<video id='webcam' autoplay playinline muted></video>
<button id='enableCam'>Enable Webcam</button>
<button class='dataCollector' data-1hot='0' data-name='Class 1'>Gather Class 1 Data</button>
<button class='dataCollector' data-1hot='1' data-name='Class 2'>Gather Class 2 Data</button>
<button id='train'>Train &amp; Predict!</button>
<button id='reset'>Reset</button>
</body>
</html>
<script>
const STATUS=document.getElementById('status');
const VIDEO=document.getElementById('webcam');
const ENABLE_CAM_BUTTON=document.getElementById('enableCam');
const RESET_BUTTON=document.getElementById('reset');
const TRAIN_BUTTON=document.getElementById('train');
const MOBILE_NET_INPUT_WIDTH=224;
const MOBILE_NET_INPUT_HEIGHT=224;
const STOP_DATA_GATHER=-1;
const CLASS_NAMES=[];

let mobilenet=undefined;
let gatherDataState=STOP_DATA_GATHER;
let videoPlaying=false;
let trainingDataInputs=[];
let trainingDataOutputs=[];
let examplesCount=[];
let predict=false;

let dataCollectorButtons=document.querySelectorAll('button.dataCollector');
for(let i=0;i<dataCollectorButtons.length;i++){
	dataCollectorButtons[i].addEventListener('mousedown',gatherDataForClass);
	dataCollectorButtons[i].addEventListener('mouseup',gatherDataForClass);
	CLASS_NAMES.push(dataCollectorButtons[i].getAttribute('data-name'))
	}

let model=tf.sequential();
model.add(tf.layers.dense({inputShape:[1024],units:128,activation:'relu'}));
model.add(tf.layers.dense({units:CLASS_NAMES.length,activation:'softmax'}));
//model.summary();
model.compile({optimizer:'adam',loss:(CLASS_NAMES.length===2)?'binaryCrossentropy':'categoricalCrossentropy',metrics:['accuracy']});

ENABLE_CAM_BUTTON.addEventListener('click',enableCam);
TRAIN_BUTTON.addEventListener('click',trainAndPredict);
RESET_BUTTON.addEventListener('click',reset);

async function loadMobileNetFeatureModel(){
	const URL='https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v3_small_100_224/feature_vector/5/default/1';
	mobilenet=await tf.loadGraphModel(URL,{fromTFHub:true});
	STATUS.innerText='Model loaded.';
	tf.tidy(function(){
		let answer=mobilenet.predict(tf.zeros([1,MOBILE_NET_INPUT_HEIGHT,MOBILE_NET_INPUT_WIDTH,3]));
		//console.log('Size of the image features:',answer.shape)
		})
		}

function hasGetUserMedia(){return !!(navigator.mediaDevices&&navigator.mediaDevices.getUserMedia)}

function enableCam(){
	if(hasGetUserMedia()){
		const constraints={video:true,width:640,height:480};
		navigator.mediaDevices.getUserMedia(constraints).then(function(stream){
			VIDEO.srcObject=stream;
			VIDEO.addEventListener('loadeddata',function(){
				videoPlaying=true;
				ENABLE_CAM_BUTTON.classList.add('removed')
				})
				})
	}else{console.warn('getUserMedia() is not supported.')}
	}

function gatherDataForClass(){
	let classNumber=parseInt(this.getAttribute('data-1hot'));
	gatherDataState=(gatherDataState===STOP_DATA_GATHER)?classNumber:STOP_DATA_GATHER;
	dataGatherLoop()
	}

function dataGatherLoop(){
	if(videoPlaying&&gatherDataState!==STOP_DATA_GATHER){
	let imageFeatures=tf.tidy(function(){
		let videoFrameAsTensor=tf.browser.fromPixels(VIDEO);
		let resizedTensorFrame=tf.image.resizeBilinear(videoFrameAsTensor,[MOBILE_NET_INPUT_HEIGHT,MOBILE_NET_INPUT_WIDTH],true);
		let normalizedTensorFrame=resizedTensorFrame.div(255);
		return mobilenet.predict(normalizedTensorFrame.expandDims()).squeeze()
		});
	trainingDataInputs.push(imageFeatures);
	trainingDataOutputs.push(gatherDataState);
	if(examplesCount[gatherDataState]===undefined){examplesCount[gatherDataState]=0}
    examplesCount[gatherDataState]++;
    STATUS.innerText='';
    for(let n=0;n<CLASS_NAMES.length;n++)STATUS.innerText+=CLASS_NAMES[n]+' data count:'+examplesCount[n]+'.';
    window.requestAnimationFrame(dataGatherLoop)
	}
	}

async function trainAndPredict(){
	predict=false;
	tf.util.shuffleCombo(trainingDataInputs,trainingDataOutputs);
	let outputsAsTensor=tf.tensor1d(trainingDataOutputs,'int32');
	let oneHotOutputs=tf.oneHot(outputsAsTensor,CLASS_NAMES.length);
	let inputsAsTensor=tf.stack(trainingDataInputs);
	let results=await model.fit(inputsAsTensor,oneHotOutputs,{shuffle:true,batchSize:5,epochs:10,callbacks:{onEpochEnd:logProgress}});
	outputsAsTensor.dispose();
	oneHotOutputs.dispose();
	inputsAsTensor.dispose();
	predict=true;
	predictLoop()
	}

function logProgress(epoch,logs){console.log('Data for Epoch '+epoch,logs)}

function predictLoop(){
	if(predict){
		tf.tidy(function(){
			let videoFrameAsTensor=tf.browser.fromPixels(VIDEO).div(255);
			let resizedTensorFrame=tf.image.resizeBilinear(videoFrameAsTensor,[MOBILE_NET_INPUT_HEIGHT,MOBILE_NET_INPUT_WIDTH],true);
			let imageFeatures=mobilenet.predict(resizedTensorFrame.expandDims());
			let prediction=model.predict(imageFeatures).squeeze();
			let highestIndex=prediction.argMax().arraySync();
			let predictionArray=prediction.arraySync();
			STATUS.innerText='Prediction:'+CLASS_NAMES[highestIndex]+' with '+Math.floor(predictionArray[highestIndex]*100)+'% confidence'
			});
		window.requestAnimationFrame(predictLoop)
		}
		}

function reset(){
	predict=false;
	examplesCount.length=0;
	for(let i=0;i<trainingDataInputs.length;i++)trainingDataInputs[i].dispose()
	trainingDataInputs.length=0;
	trainingDataOutputs.length=0;
	STATUS.innerText='Model reset.';
	console.log('Tensors in Memory:'+tf.memory().numTensors)
	}

loadMobileNetFeatureModel()
</script>
